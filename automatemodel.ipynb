{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyNluWfzg8j0Hi37oVVMqZ63",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dlogical23/capstone/blob/main/automatemodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtnahCu9ncBt",
        "outputId": "2e9617d8-d99f-4fdf-f58a-540acd4c6e39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "\n",
        "# Path to your tar.gz file\n",
        "file_path = '/content/drive/MyDrive/SIFT10M/SIFT10M.tar.gz'\n",
        "\n",
        "# Path to the directory where you want to extract the files\n",
        "extract_path = '/content/drive/MyDrive/SIFT10M'\n",
        "\n",
        "# Open the tar.gz file\n",
        "with tarfile.open(file_path, 'r:gz') as tar_ref:\n",
        "    # Extract all files to the specified directory\n",
        "    tar_ref.extractall(extract_path)"
      ],
      "metadata": {
        "id": "yd8Yqr8VntES"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqcN6ZKLu4v1",
        "outputId": "72e79e15-da1b-47a7-9396-0c0c17cd2fa6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from scipy) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the path to the tar.gz file\n",
        "tar_path = \"/content/drive/MyDrive/SIFT10M/SIFT10M.tar.gz\"\n",
        "\n",
        "# Define the extraction path\n",
        "extract_path = \"/content/drive/MyDrive/SIFT10M/extracted/\"\n",
        "\n",
        "# Ensure the extraction path exists\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Extract the tar.gz file\n",
        "try:\n",
        "    with tarfile.open(tar_path, \"r:gz\") as tar:\n",
        "        tar.extractall(path=extract_path)\n",
        "        print(f\"Extracted files to: {extract_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while extracting: {e}\")\n",
        "\n",
        "# List the extracted files\n",
        "extracted_files = os.listdir(extract_path)\n",
        "print(\"Extracted files:\", extracted_files)\n",
        "\n",
        "# Read the first 5 lines from one of the extracted text files (assuming a .txt or .csv file exists)\n",
        "for file in extracted_files:\n",
        "    file_path = os.path.join(extract_path, file)\n",
        "\n",
        "    # Check if it's a text file before reading\n",
        "    if file.endswith(\".txt\") or file.endswith(\".csv\"):\n",
        "        try:\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
        "                print(\"\\nFirst 5 lines of\", file_path)\n",
        "                for _ in range(5):\n",
        "                    print(f.readline().strip())\n",
        "            break  # Stop after reading the first valid file\n",
        "        except Exception as e:\n",
        "            print(f\"Could not read {file}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN4txCzzvR0G",
        "outputId": "112d7fc0-4c9f-4509-b0d1-1e9115451e82"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files to: /content/drive/MyDrive/SIFT10M/extracted/\n",
            "Extracted files: ['SIFT10M']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation of the Code\n",
        "Loading the Dataset:\n",
        "\n",
        "The .mat file is loaded using h5py, and the feature vectors are extracted.\n",
        "\n",
        "Similarity Search:\n",
        "\n",
        "The NearestNeighbors algorithm from scikit-learn is used to find the nearest neighbors for each feature vector.\n",
        "\n",
        "Validation:\n",
        "\n",
        "Simulated ground truth labels are used to validate the retrieved neighbors.\n",
        "\n",
        "A distance threshold is applied to filter out incorrect matches."
      ],
      "metadata": {
        "id": "an3N1o8AJJV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "# Load the .mat file using h5py\n",
        "file_path = '/content/drive/MyDrive/SIFT10M/extracted/SIFT10M/SIFT10Mfeatures.mat'\n",
        "with h5py.File(file_path, 'r') as file:\n",
        "    # Access the correct dataset. 'fea' is a common dataset name in .mat files.\n",
        "    # If 'fea' doesn't exist, inspect the file's contents to find the correct name\n",
        "    features = file['fea'][:]\n",
        "\n",
        "# View the first 5 rows\n",
        "print(features[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtpTu6VR84FH",
        "outputId": "e98bbf99-3692-438c-e538-7821aca7ddf6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 55  23  21  15  43 100 116  63 101  17   5   1   1  12  60 117  33  80\n",
            "   19   3   3  15  53  48  46  46   3   0   2   8  35  57  47  39  51  19\n",
            "   14  19  70  54  73  29   9   2   3  60 117  75 117  48   8   3  14  31\n",
            "  117 117  21  10   1   2  32  74 117  69  21   2   2  10  72  36  78  52\n",
            "   72  36  55   8   7  26  57  68 117  61  33   4  24   8   7  26  19   4\n",
            "    0   2  59  32   8   5   5   0   0   1  27   2   0   7   8   2   1   0\n",
            "    0   0   0  10   0   1   1   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [  0   0   0   0   0   0   2  10  41  22   5   0   0   0  50 123  82  64\n",
            "   28   0   0   8  53  73  95  77  40   1   0   2   7  16   1   1   2   0\n",
            "    0   0   0   2 115  51  28   0   0   0   1  37 130 119  41   0   0   0\n",
            "    0  40  64  85  63  28   2   0   7  23   1   3   3   0   0   0   0   3\n",
            "   54  65  65   0   0   0   2  57 130  57  11   0   0   0   9 128  98  24\n",
            "   13  13   1   0  22  79   4   0   0   0   0   0   0   4  73   1   0   0\n",
            "    0   1   7  82 108   2   0   0   0   1  11 130 124  16   0   0   0   6\n",
            "   23  89]\n",
            " [  0   0   0   0   0   0   0   0   9  14  25  13   4   6   2   0  38  31\n",
            "   24  17   8   4   3   9  40  39   8  14  12   2   2   6   0   0   0   0\n",
            "    1  63  21   0   9   3  14  14  10 125 105  17 125  54  20   8   0  17\n",
            "   57  75  37  58  14  21  31   7   6   3   2   6   0   0   3 125  87   0\n",
            "   52  47  25   0   1 125  56   8 125  61   8   0   0   8  27  65  30   5\n",
            "    4   5  24  55  73  16   3  81  79   7  13  45   6   0  10 125 125   1\n",
            "    0   2   2   0  35 125  68   2   1   0   2  10   2  18  28  24 125 125\n",
            "    8   3]\n",
            " [  0   2   0  12 137  81   0   0  74   8   1  30 115  19   0  16 137  20\n",
            "    0   0   0   0   0  21   4   0   0   0   0   0   0   0   0   0  14  56\n",
            "  137  24   0   0  59  11  43 117  74  17   0  14 137  26   8   8   1   4\n",
            "    5  59  27   0   0   0   1   7   5   9  25  30  32  35  43  23  10  22\n",
            "   21  42 137 137   9   0   0   0  77  72  63  48  29  25  10   9   6   1\n",
            "    4  15  23  24   9   5 137  22   0   0   0   2  10 137  18  10  14  35\n",
            "   29   6  28  25   0   1  23  74  61  15  11   2   1   1  23  30   7   7\n",
            "    4   4]\n",
            " [ 19   7  16   3   3  10  69  21  33  59  17   5  16   7   4   5  53  20\n",
            "   10   7  35  36  62 104  82   6   0   0   0   9  61 114  61  69  38   3\n",
            "    1   0  18  19 114  57  22  25  16   2   1  14  24  47 114 104  47  19\n",
            "    9  14 114 114  50   4   0   1   4  33  10  19  45  32  58  10   4   8\n",
            "  114  52  24   8   6   4   5  56  54  67 101  17   2   0   0   5  55  96\n",
            "   38   1   1   0   0  17   0   6 114  45  15   1   6   1  58 114  97  27\n",
            "    1   0   2   6  27  74  25  58  22   2   2   4  64  24   6  15   6   1\n",
            "    1  15]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load the .mat file using h5py\n",
        "file_path = '/content/drive/MyDrive/SIFT10M/extracted/SIFT10M/SIFT10Mfeatures.mat'\n",
        "with h5py.File(file_path, 'r') as file:\n",
        "    # Access the correct dataset. 'fea' is a common dataset name in .mat files.\n",
        "    # If 'fea' doesn't exist, inspect the file's contents to find the correct name\n",
        "    features = file['fea'][:]"
      ],
      "metadata": {
        "id": "Ts9dSdJdAXC6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jN1QvLx7CTOf",
        "outputId": "4b268543-aa14-4774-961a-d77d2789931a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "import h5py\n",
        "\n",
        "# Step 1: Load the SIFT10M dataset using h5py\n",
        "file_path = '/content/drive/MyDrive/SIFT10M/extracted/SIFT10M/SIFT10Mfeatures.mat'\n",
        "with h5py.File(file_path, 'r') as f:\n",
        "    # Change 'SIFT10Mfeatures' to 'fea'\n",
        "    features = f['fea'][()]  # 'fea' is the correct key for the features dataset\n",
        "    print(f\"Dataset shape: {features.shape}\")\n",
        "\n",
        "# Step 2: Normalize the feature vectors (required for faiss)\n",
        "features = features.astype('float32')  # Faiss requires float32\n",
        "faiss.normalize_L2(features)  # Normalize vectors to unit length\n",
        "\n",
        "# Step 3: Build the FAISS index\n",
        "dimension = features.shape[1]  # Dimension of feature vectors (e.g., 128 for SIFT)\n",
        "nlist = 100  # Number of clusters (adjust based on your dataset)\n",
        "quantizer = faiss.IndexFlatL2(dimension)  # Quantizer for clustering\n",
        "index = faiss.IndexIVFFlat(quantizer, dimension, nlist, faiss.METRIC_L2)\n",
        "\n",
        "# Train the index on a subset of the data\n",
        "index.train(features[:100000])  # Use a subset for training\n",
        "\n",
        "# Add all vectors to the index\n",
        "index.add(features)\n",
        "\n",
        "# Step 4: Perform ANN search\n",
        "n_neighbors = 5  # Number of neighbors to retrieve\n",
        "k = n_neighbors\n",
        "distances, indices = index.search(features[:10], k)  # Search for the first 10 queries\n",
        "\n",
        "# Display the results\n",
        "print(f\"Indices of nearest neighbors (first 10 queries):\\n{indices}\")\n",
        "print(f\"Distances to nearest neighbors (first 10 queries):\\n{distances}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwUH1LanCaxv",
        "outputId": "3877c976-7e92-46a7-c19f-4d280c037fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (11164866, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a subset of the data (e.g., first 100,000 vectors)\n",
        "subset_size = 100000\n",
        "subset_features = features[:subset_size]\n",
        "\n",
        "# Perform nearest neighbor search on the subset\n",
        "nbrs = NearestNeighbors(n_neighbors=5, algorithm=\"auto\").fit(subset_features)\n",
        "distances, indices = nbrs.kneighbors(subset_features[:10])  # Search for the first 10 queries\n",
        "\n",
        "# Display the results\n",
        "print(f\"Indices of nearest neighbors (first 10 queries):\\n{indices}\")\n",
        "print(f\"Distances to nearest neighbors (first 10 queries):\\n{distances}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tB2ocdBUBww5",
        "outputId": "97312b06-da18-4578-b96a-cb46d20a0e6e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indices of nearest neighbors (first 10 queries):\n",
            "[[    0 47983 58507 58506 43854]\n",
            " [    1 91619 30906 51883 47830]\n",
            " [    2 82912 39012 15792 88679]\n",
            " [    3 91607 89604 30291 12948]\n",
            " [    4 21594 47986 76190 96112]\n",
            " [    5   128  5829 96111 85587]\n",
            " [    6 32831 28254 29113  7276]\n",
            " [    7  1793 44513 23540 56598]\n",
            " [    8 56954  8353 38009 69447]\n",
            " [    9 27411 34409 20117  2071]]\n",
            "Distances to nearest neighbors (first 10 queries):\n",
            "[[  0.         323.39449593 335.11938171 335.11938171 340.36451049]\n",
            " [  0.         219.75440837 239.86454511 241.96074062 251.22499876]\n",
            " [  0.         274.57967878 290.3687311  299.96666481 302.61031047]\n",
            " [  0.         290.99484532 293.92856275 296.39163281 297.70119247]\n",
            " [  0.         278.44568591 284.1672043  292.38502014 293.80265486]\n",
            " [  0.         280.8558349  282.28708791 287.16545753 292.69267159]\n",
            " [  0.         257.00389102 261.00957837 267.95522014 273.52513596]\n",
            " [  0.         273.92152161 290.21888291 295.36418199 295.82089176]\n",
            " [  0.         246.39399343 262.29754097 263.63421629 266.78643144]\n",
            " [  0.         103.2036821  107.20074627 107.99537027 110.88733021]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Simulate ground truth labels (replace with actual labels if available)\n",
        "np.random.seed(42)  # For reproducibility\n",
        "labels = np.random.randint(0, 10, size=features.shape[0])  # 10 classes for demonstration\n",
        "\n",
        "# Set a distance threshold for validation\n",
        "distance_threshold = 0.5  # Adjust based on your dataset\n",
        "\n",
        "# Validate nearest neighbors for the first 5 queries\n",
        "for i in range(5):  # Check the first 5 queries\n",
        "    print(f\"\\nQuery {i}:\")\n",
        "    print(f\"  Indices of neighbors: {indices[i]}\")\n",
        "    print(f\"  Distances to neighbors: {distances[i]}\")\n",
        "\n",
        "    # Validate using ground truth labels\n",
        "    query_label = labels[i]\n",
        "    neighbor_labels = labels[indices[i]]\n",
        "    print(f\"  Query label: {query_label}, Neighbor labels: {neighbor_labels}\")\n",
        "\n",
        "    if all(neighbor_labels == query_label):\n",
        "        print(\"  Validation: All neighbors are correct!\")\n",
        "    else:\n",
        "        print(\"  Validation: Some neighbors are incorrect.\")\n",
        "\n",
        "    # Validate using distance threshold\n",
        "    if all(d < distance_threshold for d in distances[i]):\n",
        "        print(\"  Validation: All neighbors are within the threshold!\")\n",
        "    else:\n",
        "        print(\"  Validation: Some neighbors are too far away.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "iau28a8QEDd1",
        "outputId": "01d979d7-ef07-4069-e363-d8e1646d501e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'features' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c070194841a5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Simulate ground truth labels (replace with actual labels if available)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# For reproducibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 10 classes for demonstration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Set a distance threshold for validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Steps\n",
        "Replace Simulated Labels:\n",
        "\n",
        "If you have actual labels for the SIFT10M dataset, replace the simulated labels with them.\n",
        "\n",
        "Adjust the Distance Threshold:\n",
        "\n",
        "Tune the threshold based on your dataset and requirements.\n",
        "\n",
        "Scale the System:\n",
        "\n",
        "Apply the validation step to the entire dataset or integrate it into a production pipeline."
      ],
      "metadata": {
        "id": "yrV1PWaLP9Ci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "replacing labels"
      ],
      "metadata": {
        "id": "pPgeDkQzN3VA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHgjuaGxHd3Q",
        "outputId": "0468b9e9-8580-4e06-c4b4-b1810d7ccbdd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mat\n",
            "  Downloading mat-1.0.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mysql-connector-python>=8.0.20 (from mat)\n",
            "  Downloading mysql_connector_python-9.2.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from mat) (6.0.2)\n",
            "Requirement already satisfied: tabulate>=0.8.7 in /usr/local/lib/python3.11/dist-packages (from mat) (0.9.0)\n",
            "Downloading mysql_connector_python-9.2.0-cp311-cp311-manylinux_2_28_x86_64.whl (34.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.0/34.0 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: mat\n",
            "  Building wheel for mat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mat: filename=mat-1.0.2-py3-none-any.whl size=11672 sha256=c747dc6f50f1a3851718a6c3bc48d2db38140aa5fdefb3faace678018047440e\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/d5/74/536e139e8ca764ab351663048fb32cd0486411c6c41dd0c349\n",
            "Successfully built mat\n",
            "Installing collected packages: mysql-connector-python, mat\n",
            "Successfully installed mat-1.0.2 mysql-connector-python-9.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ground truth labels\n",
        "with h5py.File('/content/drive/MyDrive/SIFT10M/extracted/SIFT10M/SIFT10Mfeatures.mat', 'r') as f:\n",
        "    # The key for labels is likely 'gnd', not 'SIFT10Mlabels'\n",
        "    # Inspect the file using `h5dump -n /content/drive/MyDrive/SIFT10M/extracted/SIFT10M/SIFT10Mfeatures.mat`\n",
        "    # to confirm the correct key.\n",
        "    labels = f['fea'][()]\n",
        "    print(f\"Labels shape: {labels.shape}\")\n",
        "\n",
        "# Load the .mat file\n",
        "with h5py.File(ground_truth_path, 'r') as f:\n",
        "    # Extract the ground truth data using the key 'fea'\n",
        "    ground_truth_data = f['fea'][()]\n",
        "    print(f\"Ground truth data shape: {ground_truth_data.shape}\")\n",
        "    print(\"Ground truth data:\")\n",
        "    print(ground_truth_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUjojuiQP-w6",
        "outputId": "19cad35c-6898-44b8-98d2-57d8808af222"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels shape: (11164866, 128)\n",
            "Ground truth data shape: (11164866, 128)\n",
            "Ground truth data:\n",
            "[[ 55  23  21 ...   0   0   0]\n",
            " [  0   0   0 ...   6  23  89]\n",
            " [  0   0   0 ... 125   8   3]\n",
            " ...\n",
            " [ 70   2   0 ...  35   7   7]\n",
            " [  0   0   0 ...  86  82 102]\n",
            " [  2   0   0 ...   9   2   3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "adjusting distance"
      ],
      "metadata": {
        "id": "k_-Ewq1vNwOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu\n",
        "\n",
        "import faiss\n",
        "import numpy as np\n",
        "import h5py\n",
        "\n",
        "# Step 1: Load the SIFT10M dataset using h5py\n",
        "file_path = '/content/drive/MyDrive/SIFT10M/extracted/SIFT10M/SIFT10Mfeatures.mat'\n",
        "with h5py.File(file_path, 'r') as f:\n",
        "    # Change 'SIFT10Mfeatures' to 'fea'\n",
        "    features = f['fea'][()]  # 'fea' is the correct key for the features dataset\n",
        "    print(f\"Dataset shape: {features.shape}\")\n",
        "\n",
        "# Step 2: Normalize the feature vectors (required for faiss)\n",
        "features = features.astype('float32')  # Faiss requires float32\n",
        "faiss.normalize_L2(features)  # Normalize vectors to unit length\n",
        "\n",
        "# Step 3: Build the FAISS index\n",
        "dimension = features.shape[1]  # Dimension of feature vectors (e.g., 128 for SIFT)\n",
        "nlist = 100  # Number of clusters (adjust based on your dataset)\n",
        "quantizer = faiss.IndexFlatL2(dimension)  # Quantizer for clustering\n",
        "index = faiss.IndexIVFFlat(quantizer, dimension, nlist, faiss.METRIC_L2)\n",
        "\n",
        "# Train the index on a subset of the data\n",
        "index.train(features[:100000])  # Use a subset for training\n",
        "\n",
        "# Add all vectors to the index\n",
        "index.add(features)\n",
        "\n",
        "# Step 4: Perform ANN search\n",
        "n_neighbors = 5  # Number of neighbors to retrieve\n",
        "k = n_neighbors\n",
        "distances, indices = index.search(features[:10], k)  # Search for the first 10 queries\n",
        "\n",
        "# Display the results\n",
        "print(f\"Indices of nearest neighbors (first 10 queries):\\n{indices}\")\n",
        "print(f\"Distances to nearest neighbors (first 10 queries):\\n{distances}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGbIxar3NMlR",
        "outputId": "ed2115c9-4a3f-4c18-9ec8-2e7019348a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n",
            "Dataset shape: (11164866, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Set a distance threshold for validation\n",
        "distance_threshold = 300  # Adjust based on your dataset\n",
        "\n",
        "# Validate nearest neighbors for the first 5 queries\n",
        "for i in range(5):  # Check the first 5 queries\n",
        "    print(f\"\\nQuery {i}:\")\n",
        "    print(f\"  Indices of neighbors: {indices[i]}\")\n",
        "    print(f\"  Distances to neighbors: {distances[i]}\")\n",
        "\n",
        "    # Validate using ground truth labels\n",
        "    query_label = labels[i]\n",
        "    neighbor_labels = labels[indices[i]]\n",
        "    print(f\"  Query label: {query_label}, Neighbor labels: {neighbor_labels}\")\n",
        "\n",
        "    if all(neighbor_labels == query_label):\n",
        "        print(\"  Validation: All neighbors are correct!\")\n",
        "    else:\n",
        "        print(\"  Validation: Some neighbors are incorrect.\")\n",
        "\n",
        "        # Validate using distance threshold\n",
        "    if all(d < distance_threshold for d in distances[i]):\n",
        "        print(\"  Validation: All neighbors are within the threshold!\")\n",
        "    else:\n",
        "        print(\"  Validation: Some neighbors are too far away.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "iDeVJUDvMjLN",
        "outputId": "e290c92f-3824-457e-b392-f18ec7cd6c90"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query 0:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'indices' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a903e5f3e997>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Check the first 5 queries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nQuery {i}:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Indices of neighbors: {indices[i]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Distances to neighbors: {distances[i]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'indices' is not defined"
          ]
        }
      ]
    }
  ]
}